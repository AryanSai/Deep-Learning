{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a805e4e",
   "metadata": {},
   "source": [
    "Shallow NN -> only one hidden layer\n",
    "Deep NN -> more than one hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821ef535",
   "metadata": {},
   "source": [
    "torchvision package is for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8200b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "db11d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c92a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # <--- this means \"save in a folder called 'data'\"\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "#wrap data in dataloader\n",
    "train_dataloader =  DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8570720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_dataloader))\n",
    "print(images.shape)\n",
    "\n",
    "image, label = training_data[0]\n",
    "# print(image)\n",
    "print(image.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad90bd",
   "metadata": {},
   "source": [
    "the 1 in [1,28,28] is the number of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0fe099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image, label = training_data[0]\n",
    "\n",
    "# Remove the channel dimension for plotting (1, 28, 28) â†’ (28, 28)\n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis(\"off\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a109162f",
   "metadata": {},
   "source": [
    "## Simple Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4d3fe",
   "metadata": {},
   "source": [
    "we will have to flatten the image and dense fully connected and the softmax in the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "233dccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module): #subclassing nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() #flattening the image\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 10), #input layer\n",
    "            # nn.Linear(28*28, 128), #input layer\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(128, 10), #second layer\n",
    "            nn.ReLU(),\n",
    "            nn.Softmax(dim=1), #hidden layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x): #forward pass\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abd78e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() #set model to training mode\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        # compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step() #update weights\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() #set model to evaluation mode\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67dce77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303067 [    0/60000]\n",
      "loss: 2.301851 [ 6400/60000]\n",
      "loss: 2.303126 [12800/60000]\n",
      "loss: 2.300195 [19200/60000]\n",
      "loss: 2.302433 [25600/60000]\n",
      "loss: 2.294687 [32000/60000]\n",
      "loss: 2.292063 [38400/60000]\n",
      "loss: 2.287810 [44800/60000]\n",
      "loss: 2.287885 [51200/60000]\n",
      "loss: 2.286772 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 22.0%, Avg loss: 2.289911 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.283913 [    0/60000]\n",
      "loss: 2.293294 [ 6400/60000]\n",
      "loss: 2.286289 [12800/60000]\n",
      "loss: 2.288443 [19200/60000]\n",
      "loss: 2.298181 [25600/60000]\n",
      "loss: 2.269443 [32000/60000]\n",
      "loss: 2.268938 [38400/60000]\n",
      "loss: 2.257067 [44800/60000]\n",
      "loss: 2.261197 [51200/60000]\n",
      "loss: 2.260507 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 25.2%, Avg loss: 2.268952 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.253229 [    0/60000]\n",
      "loss: 2.279170 [ 6400/60000]\n",
      "loss: 2.259092 [12800/60000]\n",
      "loss: 2.268875 [19200/60000]\n",
      "loss: 2.289553 [25600/60000]\n",
      "loss: 2.236125 [32000/60000]\n",
      "loss: 2.235352 [38400/60000]\n",
      "loss: 2.218098 [44800/60000]\n",
      "loss: 2.217438 [51200/60000]\n",
      "loss: 2.225041 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 28.5%, Avg loss: 2.239563 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.207258 [    0/60000]\n",
      "loss: 2.247818 [ 6400/60000]\n",
      "loss: 2.215249 [12800/60000]\n",
      "loss: 2.238768 [19200/60000]\n",
      "loss: 2.277021 [25600/60000]\n",
      "loss: 2.196560 [32000/60000]\n",
      "loss: 2.195355 [38400/60000]\n",
      "loss: 2.174821 [44800/60000]\n",
      "loss: 2.168438 [51200/60000]\n",
      "loss: 2.190181 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 29.2%, Avg loss: 2.210498 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.161914 [    0/60000]\n",
      "loss: 2.218092 [ 6400/60000]\n",
      "loss: 2.178364 [12800/60000]\n",
      "loss: 2.213581 [19200/60000]\n",
      "loss: 2.267825 [25600/60000]\n",
      "loss: 2.167149 [32000/60000]\n",
      "loss: 2.165646 [38400/60000]\n",
      "loss: 2.145031 [44800/60000]\n",
      "loss: 2.140139 [51200/60000]\n",
      "loss: 2.167836 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 29.3%, Avg loss: 2.192748 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model =  NeuralNetwork()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss() #loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) #stochastic gradient descent\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee7f4e",
   "metadata": {},
   "source": [
    "Test Error: \n",
    " Accuracy: 53.6%, Avg loss: 2.079146 \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97ca56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
